{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f22f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU memory flushed.\n",
      "▶ Test examples: 1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rehab/research/whisperlaz/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from dataclasses import dataclass\n",
    "import gc\n",
    "\n",
    "def flush_gpu():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    print(\"✅ GPU memory flushed.\")\n",
    "\n",
    "flush_gpu()\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    MANIFEST_CSV = \"./manifest/preprocessed-segments-index.csv\"\n",
    "    TEST_RATIO   = 0.1\n",
    "    SEED         = 42\n",
    "    BATCH_SIZE   = 4\n",
    "    DEVICE       = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # list your fine-tuned model and any baselines you want to compare\n",
    "    MODEL_LIST   = [\n",
    "        \"./whisper-ja-asmr-distil-whisper-large-v3-ja-reazonspeech-all-1-earlyst-normalize-warm-lora-baonly/final-merged\",\n",
    "        \"./whisper-ja-asmr-tiny-1-earlyst/final\",\n",
    "        \"./whisper-ja-asmr-small-1-earlyst/final\",\n",
    "        \"./whisper-ja-asmr-tiny-2-earlyst-normalize-warm/final\",\n",
    "        \"openai/whisper-tiny\",\n",
    "        \"openai/whisper-small\",\n",
    "        \"openai/whisper-medium\",\n",
    "        \"openai/whisper-large-v3\",\n",
    "        \"japanese-asr/distil-whisper-large-v3-ja-reazonspeech-all\",\n",
    "        # \"japanese-asr/distil-whisper-large-v3-ja-reazonspeech-tiny\",\n",
    "        # \"japanese-asr/distil-whisper-large-v3-ja-reazonspeech-medium\",\n",
    "        # \"japanese-asr/distil-whisper-large-v3-ja-reazonspeech-small\",\n",
    "    ]\n",
    "    # these hyperparameters will be *identical* across every model:\n",
    "    GENERATION_KWARGS = {\n",
    "        \"num_beams\":            3,\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"repetition_penalty\":   1.5,\n",
    "        \"length_penalty\":       1.0,\n",
    "        \"early_stopping\":       True,\n",
    "        \"max_new_tokens\":       50,\n",
    "    }\n",
    "\n",
    "# 1) load & split test set\n",
    "df = pd.read_csv(Config.MANIFEST_CSV)\n",
    "df = df[df.lang == \"ja\"].reset_index(drop=True)\n",
    "_, test_df = np.split(\n",
    "    df.sample(frac=1, random_state=Config.SEED),\n",
    "    [ int(len(df)*(1 - Config.TEST_RATIO)) ]\n",
    ")\n",
    "print(f\"▶ Test examples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e2b0ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# 2) prepare metrics\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "\n",
    "# 3) batched evaluation function\n",
    "import torch.nn.functional as F  # ← add this at top of your script\n",
    "\n",
    "def evaluate_model(model_name: str):\n",
    "    is_local = model_name.startswith(\"./\")\n",
    "    print(f\"\\n→ Evaluating: {model_name} ({'local' if is_local else 'hub'})\")\n",
    "    processor = WhisperProcessor.from_pretrained(model_name)\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_name).to(Config.DEVICE)\n",
    "\n",
    "    # clear any forced tokens\n",
    "    model.generation_config.forced_decoder_ids = None\n",
    "    model.generation_config.suppress_tokens      = []\n",
    "\n",
    "    # apply shared hyperparameters\n",
    "    for k, v in Config.GENERATION_KWARGS.items():\n",
    "        setattr(model.generation_config, k, v)\n",
    "\n",
    "    preds, refs = [], []\n",
    "    n = len(test_df)\n",
    "    for start in tqdm(range(0, n, Config.BATCH_SIZE), desc=\"  batches\"):\n",
    "        batch = test_df.iloc[start : start + Config.BATCH_SIZE]\n",
    "        audio_list, txt_list = [], []\n",
    "        for npz_path in batch.npz_path:\n",
    "            data = np.load(npz_path, allow_pickle=True)\n",
    "            audio_list.append(data[\"audio\"].astype(np.float32))\n",
    "            txt_list.append(str(data[\"text\"]))\n",
    "        refs.extend(txt_list)\n",
    "\n",
    "        # --- FIXED BLOCK: pad/trim to fixed mel‐feature length ---\n",
    "        inputs = processor(\n",
    "            audio_list,\n",
    "            sampling_rate=16_000,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        # shape: (batch, n_mels, seq_len)\n",
    "        input_feats    = inputs.input_features.to(Config.DEVICE)\n",
    "        # shape: (batch, seq_len)\n",
    "        attention_mask = inputs.attention_mask.to(Config.DEVICE)\n",
    "\n",
    "        # compute required length: max_source_positions * conv1.stride * conv2.stride\n",
    "        c1 = model.model.encoder.conv1.stride[0]\n",
    "        c2 = model.model.encoder.conv2.stride[0]\n",
    "        expected_len = model.config.max_source_positions * c1 * c2\n",
    "\n",
    "        seq_len = input_feats.shape[-1]\n",
    "        if seq_len < expected_len:\n",
    "            pad_amt = expected_len - seq_len\n",
    "            # pad last dimension (time) by pad_amt\n",
    "            input_feats    = F.pad(input_feats,    (0, pad_amt))\n",
    "            attention_mask = F.pad(attention_mask, (0, pad_amt))\n",
    "        elif seq_len > expected_len:\n",
    "            input_feats    = input_feats[..., :expected_len]\n",
    "            attention_mask = attention_mask[..., :expected_len]\n",
    "        # -----------------------------------------------------------\n",
    "\n",
    "        with torch.no_grad():\n",
    "            gen_ids = model.generate(\n",
    "                input_feats,\n",
    "                attention_mask=attention_mask,\n",
    "            )\n",
    "\n",
    "        batch_preds = processor.batch_decode(gen_ids, skip_special_tokens=True)\n",
    "        preds.extend(batch_preds)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=preds, references=refs)\n",
    "    cer = cer_metric.compute(predictions=preds, references=refs)\n",
    "    print(f\"    WER: {wer:.3f}   CER: {cer:.3f}\")\n",
    "    return {\"wer\": wer, \"cer\": cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae6d0310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Evaluating: ./whisper-ja-asmr-distil-whisper-large-v3-ja-reazonspeech-all-1-earlyst-normalize-warm-lora-baonly/final-merged (local)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97973d71265431699652fbfe3f29c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  batches:   0%|          | 0/425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`generation_config` default values have been modified to match model-specific defaults: {'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}. If this is not desired, please set these values explicitly.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> to see related `.generate()` flags.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> to see related `.generate()` flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WER: 0.917   CER: 0.292\n",
      "\n",
      "→ Evaluating: ./whisper-ja-asmr-tiny-1-earlyst/final (local)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e2178727b146bb946fe2b41bcc77e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  batches:   0%|          | 0/425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WER: 1.097   CER: 0.942\n",
      "\n",
      "→ Evaluating: ./whisper-ja-asmr-small-1-earlyst/final (local)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df8328dd4414d9a90455a32e71fa09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  batches:   0%|          | 0/425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WER: 1.096   CER: 0.611\n",
      "\n",
      "→ Evaluating: ./whisper-ja-asmr-tiny-2-earlyst-normalize-warm/final (local)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbcdd12df4f45bc878919cc30010251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  batches:   0%|          | 0/425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WER: 1.127   CER: 1.270\n",
      "\n",
      "→ Evaluating: openai/whisper-tiny (hub)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5fd0636563423cad7b8368e5503fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  batches:   0%|          | 0/425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WER: 4.770   CER: 1.674\n",
      "\n",
      "→ Evaluating: openai/whisper-small (hub)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1d5cffbdaa4835957ef964bdec38b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  batches:   0%|          | 0/425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WER: 4.852   CER: 1.867\n",
      "\n",
      "→ Evaluating: openai/whisper-medium (hub)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d457ed8f8a0f47b9b7d9c912bae0f7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  batches:   0%|          | 0/425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WER: 5.025   CER: 1.915\n",
      "\n",
      "→ Evaluating: openai/whisper-large-v3 (hub)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406b9824950e42bd9617ec14e2b7417b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  batches:   0%|          | 0/425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WER: 5.342   CER: 1.988\n",
      "\n",
      "→ Evaluating: japanese-asr/distil-whisper-large-v3-ja-reazonspeech-all (hub)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b33c0b022241ebbaafdade0fb33075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  batches:   0%|          | 0/425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WER: 0.953   CER: 0.405\n"
     ]
    }
   ],
   "source": [
    "# 4) loop through all models\n",
    "results = {}\n",
    "for model_name in Config.MODEL_LIST:\n",
    "    results[model_name] = evaluate_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d333f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Comparison\n",
      "                                               model       wer       cer\n",
      "0  ./whisper-ja-asmr-distil-whisper-large-v3-ja-r...  0.916911  0.291941\n",
      "1             ./whisper-ja-asmr-tiny-1-earlyst/final  1.097356  0.941794\n",
      "2            ./whisper-ja-asmr-small-1-earlyst/final  1.095678  0.610665\n",
      "3  ./whisper-ja-asmr-tiny-2-earlyst-normalize-war...  1.126731  1.270193\n",
      "4                                openai/whisper-tiny  4.770038  1.674027\n",
      "5                               openai/whisper-small  4.852287  1.866936\n",
      "6                              openai/whisper-medium  5.025178  1.914799\n",
      "7                            openai/whisper-large-v3  5.341586  1.988444\n",
      "8  japanese-asr/distil-whisper-large-v3-ja-reazon...  0.953000  0.405017\n"
     ]
    }
   ],
   "source": [
    "# 5) summary\n",
    "df_results = pd.DataFrame([\n",
    "    {\"model\": m, **metrics}\n",
    "    for m, metrics in results.items()\n",
    "])\n",
    "print(\"\\n### Comparison\")\n",
    "print(df_results)\n",
    "df_results.to_csv(\"./manifest/model-comparison-evals.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4bb1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
